{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outro Transition Models\n",
    "In this notebook, we will train two models, which, when taken together, will allow us to identify start and end of transition points in the outro of an input song. We will use a fairly similar approach to the one described in the [Introduction Models notebook](2.%20Introduction%20Transition%20Models.ipynb). However, the training task is more difficult in the outro, as we do not have the start of the song as a direct anchor point, and the end of a song cannot provide reliable beat/downbeat information in the same way that the start of the song can. \n",
    "\n",
    "We will therefore need to invert the process taken for our Introduction models. In constructing that process, we first determined the timestamp of the first downbeat of the first phrase, then trained a timing model which was agnostic to specific phrase locations. We could then use the first downbeat timestamp to pick out where the transition points should occur in every subsequent phrase by taking 32 beat jumps. For the outro models we are going to need to use the timing model first, in order to determine the period of the song where the outro actually begins and therefore where the transition should begin. We will then apply a separate Start Bar Finder similar to the one trained for the Introduction models to narrow down that period and pinpoint the specific bar where the transition should begin. For songs which our Introduction models predicted that the first downbeat is on the first beat, we will calculate the BPM of the song and use it to build a downbeat grid which can take advantage of the uniform tempo structure of EDM to identify phrase points in the outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Concatenate, \\\n",
    "Embedding,ReLU,Flatten,Dropout,BatchNormalization,Activation,Dot\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D,LSTM,Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(40)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imports\n",
    "We begin by importing our labelled data and chromagram/spectrogram audio data. We have stored these as pickled dictionaries of dataframes and numpy arrays respectively. We also define the same helper functions as for the Introduction models, and perform the same processing to slice the spectrograms, and truncate/pad the slices to a uniform size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('grams_full.pkl','rb') as f:\n",
    "    full_grams = pickle.load(f)\n",
    "\n",
    "with open('labels_dict','rb') as f:\n",
    "    labels_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohs(df):\n",
    "    \"\"\"Given a labelled bar/beats input, appends columns with binary\n",
    "        indicators at each beat, with 1 at the appropriate transition\n",
    "        points and 0 otherwise.\n",
    "        \n",
    "        Args:\n",
    "            df: Bar/beats dataframe with 'Start' and 'End' transition \n",
    "                labels in intro and outro\n",
    "        \n",
    "        Returns:\n",
    "            df_copy: Copy of the dataframe with four columns of binary\n",
    "                labels appended: Incoming Start, Incoming End, Outgoing\n",
    "                Start, Outgoing End\n",
    "        \"\"\"\n",
    "    df_copy = df.copy(deep=True)\n",
    "    \n",
    "    df_copy['Incoming Start'] = df_copy['Intro Label'].apply(\n",
    "        lambda x: int('Start' in str(x)))\n",
    "    df_copy['Incoming End'] = df_copy['Intro Label'].apply(\n",
    "        lambda x: int('End' in str(x)))\n",
    "    df_copy['Outgoing Start'] = df_copy['Outro Label'].apply(\n",
    "        lambda x: int('Start' in str(x)))\n",
    "    df_copy['Outgoing End'] = df_copy['Outro Label'].apply(\n",
    "        lambda x: int('End' in str(x)))\n",
    "    \n",
    "    df_copy = df_copy.drop(['Intro Label','Outro Label'],axis=1)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def get_slices(gram,frames):\n",
    "    \"\"\"Utility function for slicing a spectrogram/chromagram according\n",
    "        to frames.\n",
    "        \n",
    "        Args:\n",
    "            gram: Spectrogram or chromagram numpy array\n",
    "            frames: indices at which to slice array\n",
    "            \n",
    "        Returns:\n",
    "            List of array slices\n",
    "        \"\"\"\n",
    "    return [gram[frames[i]:frames[i+1]] for i in range(len(frames)-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_pad(outputs,length= 175):\n",
    "    \"\"\"Truncates or pads gram slices to be of input length\n",
    "        \n",
    "        Args: \n",
    "            outputs: length two list containing chromagram and spectrogram \n",
    "                inputs, i.e. list of four-beat slices\n",
    "            length: axis 0 length of output of each slice\n",
    "        \n",
    "        Returns:\n",
    "            length two list of truncated/padded chromagrams and spectrograms\n",
    "    \"\"\"\n",
    "    chromagram,spectrogram = outputs\n",
    "    \n",
    "    size = spectrogram.shape[0]\n",
    "    #We convert the spectrogram power values to db and divide by -80 \n",
    "    #so that all values are between 0 and 1\n",
    "    spectrogram = librosa.power_to_db(spectrogram.T, ref=np.max).T/-80.0\n",
    "    \n",
    "    \n",
    "    if size>=length:\n",
    "        return [x[:length] for x in [chromagram,spectrogram]]\n",
    "    else:\n",
    "        zeros_x = length-size\n",
    "        zeros_chromagram = np.zeros((zeros_x,12))\n",
    "        zeros_spectrogram = np.zeros((zeros_x,128))\n",
    "        \n",
    "        return [np.concatenate([chromagram,zeros_chromagram],axis = 0).astype(np.float32),\n",
    "               np.concatenate([spectrogram,zeros_spectrogram],axis = 0).astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_length = 175\n",
    "gram_slices_tp = {}\n",
    "gram_slice_times = {}\n",
    "for song in [x for x in labels_dict if x in full_grams]:\n",
    "    grams = full_grams[song]\n",
    "    full_gram_shape = grams[0].shape[0]\n",
    "    \n",
    "    tags = labels_dict[song]\n",
    "    tags['Frame'] = librosa.time_to_frames(tags.values[:,0],sr=22050,hop_length=256)\n",
    "    \n",
    "    if tags.shape[0]%4==0:\n",
    "        indices = [i*4 for i in range(tags.shape[0]//4)]\n",
    "    else:\n",
    "        indices = [i*4 for i in range(1+tags.shape[0]//4)]\n",
    "    frames = tags.values[indices,-1].astype(np.int32).tolist()\n",
    "    if full_gram_shape not in frames:\n",
    "        frames.append(full_gram_shape)\n",
    "    \n",
    "    times = tags.values[indices,0].tolist()\n",
    "    gram_slice_times[song] = times\n",
    "    \n",
    "    chromagrams,spectrograms = [get_slices(gram,frames) for gram in grams]\n",
    "    \n",
    "    #We check to make sure there are no empty slices, and add zeros at the start and end\n",
    "    non_zero_inds = [x for x in range(len(spectrograms)) if spectrograms[x].shape[0]>0]\n",
    "    \n",
    "    chromagrams = [chromagrams[i] for i in non_zero_inds]\n",
    "    chromagrams = [np.zeros((slice_length,12))]+chromagrams+[np.zeros((slice_length,12))]\n",
    "    \n",
    "    spectrograms = [spectrograms[i] for i in non_zero_inds]\n",
    "    spectrograms = [np.zeros((slice_length,128))]+spectrograms+[np.zeros((slice_length,128))]\n",
    "    \n",
    "    #We now perform the truncation/padding\n",
    "    gram_slices_tp[song] = list(zip(*[truncate_pad(\n",
    "        x) for x in zip(*[chromagrams,spectrograms])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outro Transition Timing\n",
    "We will first train a model similar to the Introduction transition timing model trained in the [Introduction Models notebook](2.%20Introduction%20Transition%20Models.ipynb). As before, it will consist of 1D convolution on four-beat chunks which are then input into a Bidirectional LSTM. The input will be the last 256 beats of the song, and the training labels are binary labels on each bar of whether the transition should start or end on that bar.\n",
    "### Data Preparation\n",
    "We need to extract the binary start/end labels from the labelled beats for each song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_seq_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohs_dict = {}\n",
    "timing_model_labels = {}\n",
    "for song in gram_slices_tp:\n",
    "    tags = labels_dict[song]\n",
    "    ohs = get_ohs(tags)\n",
    "    ohs_dict[song] = ohs\n",
    "    \n",
    "    indices = [i*4 for i in range(tags.shape[0]//4)]\n",
    "    ohs_slices = [ohs.values[indices[i]:indices[i+1],-2:] for i in range(len(indices)-1)]\n",
    "    ohs_slices += [ohs.values[indices[-1]:,-2:]]\n",
    "    ohs_slices = ohs_slices[-1*tm_seq_len:]\n",
    "    slice_labels = [np.max(slce,axis = 0) for slce in ohs_slices if slce.shape[0]!=0] \n",
    "    slice_labels.append(np.array([0,0]))\n",
    "    while len(slice_labels) < tm_seq_len + 1:\n",
    "        slice_labels = [np.array([0,0])] + slice_labels\n",
    "    timing_model_labels[song] = slice_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timing_model_inputs(song):\n",
    "    \"\"\"Takes a song as input and returns stacked and concatenated\n",
    "        array slices representing the last 256 beats of the song.\n",
    "    \"\"\"\n",
    "    chromagrams,spectrograms = gram_slices_tp[song]\n",
    "    \n",
    "    chromagrams_inp = np.stack(chromagrams[-(tm_seq_len+1):])\n",
    "    spectrograms_inp = np.stack(spectrograms[-(tm_seq_len+1):])\n",
    "    \n",
    "    if chromagrams_inp.shape[0] < tm_seq_len + 1:\n",
    "        padding_needed = tm_seq_len + 1 - chromagrams_inp.shape[0]\n",
    "        zeros_pad_chromagram = np.zeros((padding_needed,slice_length,12))\n",
    "        chromagrams_inp = np.concatenate([zeros_pad_chromagram,chromagrams_inp],\n",
    "                                        axis = 0)\n",
    "        \n",
    "        zeros_pad_spectrogram = np.zeros((padding_needed,slice_length,128))\n",
    "        spectrograms_inp = np.concatenate([zeros_pad_spectrogram,spectrograms_inp],\n",
    "                                        axis = 0)\n",
    "        \n",
    "    return np.concatenate([chromagrams_inp,spectrograms_inp],axis = -1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the [Introduction Models notebook](2.%20Introduction%20Transition%20Models.ipynb), we implement an approach to sample weighting which allows the model to focus on the positive labels. In the Introduction Models, we only needed to take into consideration the previous label when determining the weight, but for the outro we need to take into account the previous and the subsequent labels, as some outros end more than 32 beats before the end of the song. We also want to place more weight on the first positive label and surrounding predictions, as this is what will be used to determine the overall transition timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_weight(i,sums,other_weight=0.01):\n",
    "    \"\"\"Determines training weights for transition timing model. \n",
    "        All bars with positive labels are set at 1, along with the \n",
    "        other bars which are multiples of eight bars (i.e. a phrase) \n",
    "        away and within 32 bars (or four phrases).\n",
    "        \n",
    "        Args:\n",
    "            i: Index in sliced label input\n",
    "            sums: List of sum of labels at each index.\n",
    "            other_weight: Scaling weight for less important inputs\n",
    "            \n",
    "        Returns:\n",
    "            Scaled weight (either 1 or other_weight)\n",
    "    \"\"\"\n",
    "    factor = other_weight/(1-other_weight)\n",
    "    if i > len(sums)-9:\n",
    "        return (int(\n",
    "            sums[i]!=0 or sums[i-8]!=0 or sums[i-16]!=0)+factor)/(1+factor)\n",
    "    elif i > len(sums) - 17:\n",
    "        return (int(\n",
    "            sums[i]!=0 or sums[i+8]!=0 or sums[i-8]!=0 or sums[i-16]!=0)+factor)/(1+factor)\n",
    "    elif i > len(sums) - 25:\n",
    "        return (int(\n",
    "            sums[i]!=0 or sums[i+8]!=0 or sums[i+16]!=0 or sums[i-8]!=0)+factor)/(1+factor)\n",
    "    elif i > len(sums) - 33:\n",
    "        return (int(\n",
    "            sums[i]!=0 or sums[i+8]!=0 or sums[i+16]!=0 or sums[i+24]!=0)+factor)/(1+factor)\n",
    "    else:\n",
    "        return (int(\n",
    "            sums[i]!=0 or sums[i+8]!=0 or sums[i+16]!=0 or sums[i+24]!=0 or sums[i+32]!=0)+factor)/(\n",
    "            1+factor)\n",
    "\n",
    "\n",
    "def get_weights(song):\n",
    "    \"\"\"Wrapper function for get_single_weight function to apply\n",
    "        to full label input for a song. Multiplies the first\n",
    "        positive example weight and the preceding weight by 1.5\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = timing_model_labels[song]\n",
    "    sums = [np.sum(label) for label in labels]\n",
    "    weights = [get_single_weight(i,sums) for i in range(len(sums))]\n",
    "    pos_weight_indices = [i for i in range(len(weights)) if weights[i] > 0.5 and sums[i]!=0]\n",
    "    first_pos_weight_ind = pos_weight_indices[0]\n",
    "    weights[first_pos_weight_ind] *= 1.5\n",
    "    if first_pos_weight_ind >= 8:\n",
    "        weights[first_pos_weight_ind-8] *= 1.5\n",
    "        \n",
    "    return weights\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the same validation and test sets as were used for the intro models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sc_vad_set.pkl','rb') as f:\n",
    "    vad_set = pickle.load(f)\n",
    "\n",
    "with open('sc_test_set.pkl','rb') as f:\n",
    "    test_set = pickle.load(f)\n",
    "    \n",
    "train_set = [x for x in gram_slices_tp if x not in vad_set and x not in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_train_input = np.stack(\n",
    "    [get_timing_model_inputs(song) for song in train_set]).astype('float32')\n",
    "tm_train_target = np.stack(\n",
    "    [timing_model_labels[song] for song in train_set]).astype('float32')\n",
    "tm_train_weights = np.stack(\n",
    "    [get_weights(song) for song in train_set]).astype('float32')\n",
    "\n",
    "tm_vad_input = np.stack(\n",
    "    [get_timing_model_inputs(song) for song in vad_set]).astype('float32')\n",
    "tm_vad_target = np.stack(\n",
    "    [timing_model_labels[song] for song in vad_set]).astype('float32')\n",
    "tm_vad_weights = np.stack(\n",
    "    [get_weights(song) for song in vad_set]).astype('float32')\n",
    "\n",
    "tm_test_input = np.stack(\n",
    "    [get_timing_model_inputs(song) for song in test_set]).astype('float32')\n",
    "tm_test_target = np.stack(\n",
    "    [timing_model_labels[song] for song in test_set]).astype('float32')\n",
    "tm_test_weights = np.stack(\n",
    "    [get_weights(song) for song in test_set]).astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_gram_in = Input((slice_length,140),name = 'tm_analysis_in')\n",
    "\n",
    "tm_conv_bar_c = Conv1D(filters = 16,kernel_size = 11,activation = 'relu',strides = 3)\n",
    "tm_pool_bar_c = MaxPooling1D(pool_size = 2,strides = 2)\n",
    "tm_bar_out_c = BatchNormalization()(tm_pool_bar_c(tm_conv_bar_c(tm_gram_in)))\n",
    "\n",
    "tm_conv_bar_2_c = Conv1D(filters = 8,kernel_size = 2,activation = 'relu',strides = 2)\n",
    "tm_pool_bar_2_c = MaxPooling1D(pool_size = 1,strides =1)\n",
    "tm_bar_out_2_c = BatchNormalization()(tm_pool_bar_2_c(tm_conv_bar_2_c(tm_bar_out_c)))\n",
    "\n",
    "tm_bar_out_c_flat = Flatten()(tm_bar_out_2_c)\n",
    "tm_gram_model = Model(tm_gram_in,tm_bar_out_c_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_gram_input = Input((tm_seq_len+1,175,140))\n",
    "tm_gram_flat = Lambda(lambda x: K.reshape(x,(-1,175,140)))(tm_gram_input)\n",
    "\n",
    "tm_conv = tm_gram_model(tm_gram_flat)\n",
    "\n",
    "tm_conv_seq = Lambda(lambda x: K.reshape(x,(-1,tm_seq_len+1,tm_conv.shape[-1])))(tm_conv)\n",
    "\n",
    "\n",
    "tm_conv_dense = Dense(48,activation='tanh')(Dropout(rate=0.4)(tm_conv_seq))\n",
    "tm_conv_dense_2 = Dense(32,activation='tanh')(Dropout(rate=0.4)(tm_conv_dense))\n",
    "\n",
    "tm_lstm_out = Bidirectional(LSTM(\n",
    "    48,return_sequences=True,recurrent_dropout = 0.45,dropout=0.45))(tm_conv_dense_2)\n",
    "tm_dense_1 = Dense(16,activation='tanh')(Dropout(rate=0.4)(tm_lstm_out))\n",
    "tm_out = Dense(2,activation='sigmoid')(Dropout(rate=0.3)(tm_dense_1))\n",
    "tm_final_model = Model(tm_gram_input,tm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "We train the model using the same approach as in the Introduction case, with early stopping based on the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_adam_opt = tf.keras.optimizers.Adam(lr = 2e-4)\n",
    "\n",
    "tm_final_model.compile(optimizer = tm_adam_opt, loss = 'binary_crossentropy',\n",
    "                    weighted_metrics = ['accuracy'],sample_weight_mode='temporal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tm_final_model.fit(tm_train_input,tm_train_target,batch_size = 16,\n",
    "                sample_weight=tm_train_weights,epochs = 100,\n",
    "                   validation_data = (tm_vad_input,tm_vad_target,tm_vad_weights),\n",
    "                  verbose = 0)\n",
    "\n",
    "tm_es = EarlyStopping(restore_best_weights=True,monitor='val_loss',patience=20)\n",
    "tm_final_model.fit(tm_train_input,tm_train_target,batch_size = 16,\n",
    "                sample_weight=tm_train_weights,epochs = 200,\n",
    "                   validation_data = (tm_vad_input,tm_vad_target,tm_vad_weights),\n",
    "                  callbacks = [tm_es],verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_train_pred = tm_final_model.predict(tm_train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance:\n",
      "30/30 [==============================] - 3s 88ms/step - loss: 0.0339 - accuracy: 0.8424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03390813618898392, 0.8424115777015686]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training performance:')\n",
    "tm_final_model.evaluate(tm_train_input,tm_train_target,sample_weight=tm_train_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance:\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0327 - accuracy: 0.8506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03266860172152519, 0.85056072473526]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Validation performance:')\n",
    "tm_final_model.evaluate(tm_vad_input,tm_vad_target,sample_weight=tm_vad_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance:\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0363 - accuracy: 0.8492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.036313679069280624, 0.8491887450218201]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test performance:')\n",
    "tm_final_model.evaluate(tm_test_input,tm_test_target,sample_weight=tm_test_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine an example song to see what our predictions look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transition Start Label</th>\n",
       "      <th>Transition End Label</th>\n",
       "      <th>Start Probability</th>\n",
       "      <th>End Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Transition Start Label  Transition End Label  Start Probability  \\\n",
       "31                     0.0                   0.0               0.08   \n",
       "32                     0.0                   0.0               0.09   \n",
       "33                     0.0                   0.0               0.11   \n",
       "34                     0.0                   0.0               0.15   \n",
       "35                     0.0                   0.0               0.20   \n",
       "36                     0.0                   0.0               0.27   \n",
       "37                     0.0                   0.0               0.35   \n",
       "38                     0.0                   0.0               0.47   \n",
       "39                     0.0                   0.0               0.51   \n",
       "40                     1.0                   0.0               0.52   \n",
       "41                     0.0                   0.0               0.50   \n",
       "42                     0.0                   0.0               0.47   \n",
       "43                     0.0                   0.0               0.43   \n",
       "44                     0.0                   0.0               0.38   \n",
       "45                     0.0                   0.0               0.32   \n",
       "46                     0.0                   0.0               0.35   \n",
       "47                     0.0                   0.0               0.29   \n",
       "48                     1.0                   1.0               0.25   \n",
       "49                     0.0                   0.0               0.22   \n",
       "50                     0.0                   0.0               0.20   \n",
       "51                     0.0                   0.0               0.17   \n",
       "52                     0.0                   0.0               0.15   \n",
       "53                     0.0                   0.0               0.13   \n",
       "54                     0.0                   0.0               0.11   \n",
       "55                     0.0                   0.0               0.08   \n",
       "56                     0.0                   1.0               0.06   \n",
       "57                     0.0                   0.0               0.04   \n",
       "58                     0.0                   0.0               0.03   \n",
       "59                     0.0                   0.0               0.02   \n",
       "60                     0.0                   0.0               0.02   \n",
       "61                     0.0                   0.0               0.02   \n",
       "62                     0.0                   0.0               0.01   \n",
       "63                     0.0                   1.0               0.01   \n",
       "64                     0.0                   0.0               0.01   \n",
       "\n",
       "    End Probability  \n",
       "31             0.02  \n",
       "32             0.02  \n",
       "33             0.02  \n",
       "34             0.03  \n",
       "35             0.03  \n",
       "36             0.03  \n",
       "37             0.04  \n",
       "38             0.04  \n",
       "39             0.06  \n",
       "40             0.08  \n",
       "41             0.09  \n",
       "42             0.12  \n",
       "43             0.16  \n",
       "44             0.21  \n",
       "45             0.28  \n",
       "46             0.25  \n",
       "47             0.38  \n",
       "48             0.44  \n",
       "49             0.50  \n",
       "50             0.56  \n",
       "51             0.61  \n",
       "52             0.66  \n",
       "53             0.70  \n",
       "54             0.72  \n",
       "55             0.78  \n",
       "56             0.81  \n",
       "57             0.84  \n",
       "58             0.86  \n",
       "59             0.89  \n",
       "60             0.91  \n",
       "61             0.93  \n",
       "62             0.95  \n",
       "63             0.92  \n",
       "64             0.04  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.DataFrame(np.stack(timing_model_labels['Chris Lake - Lose My Mind']),\n",
    "            columns = ['Transition Start Label','Transition End Label'])\n",
    "\n",
    "example_pred = np.round(\n",
    "    tm_final_model.predict(\n",
    "        tm_train_input[[train_set.index('Chris Lake - Lose My Mind')]]),2)[0]\n",
    "\n",
    "example_df = pd.concat([example_df,\n",
    "                        pd.DataFrame(example_pred,\n",
    "                                     columns = ['Start Probability','End Probability'])],axis=1)\n",
    "\n",
    "example_df.iloc[-34:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outro Start Bar Finder\n",
    "Now that we have a model which can determine rough timings for the transition, we need to narrow those timings down. As discussed above, we do not have the advantage of the start of the song providing a fixed reference point from which to identify the starting bar. Instead, we will have to use the output of the timing model to give us a window in which we can narrow down the correct bar. We will want the model to be predicting around the point where the Start Probability exceeds 0.5 for the first time; in the example directly above, this is at index 38, so we might want the model to be predicting the starting bar over bars 36 to 44, with the correct bar being bar 40.\n",
    "\n",
    "We will train a model which is similar in architecture to the Intro Start Bar Finder for this purpose. However, the training regime will be different, as we want to provide the model with a more diverse range of starting points around the first label. We will therefore train the model on randomly sampled batches of songs and starting points which are within eight bars of the first Start label. We will also need to give the model more context; in the introduction model, only the 'right' context is available since to the 'left' is the start of the song. In this case however it is likely that both left and right context will be relevant.\n",
    "### Data Preparation\n",
    "Rather than building a fixed training set, we are going to define a method for sampling individual training batches. To make this easier, we first extract from our sliced grams a fixed-length sequence for each song. The total sequence length of the model input will be 32, so we construct sequences of length 40 with the correct starting label exactly in the middle at index 20. We can then easily generate a training example of length 32 with the correct label being at any index between 16 and 24. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_slices_sbf = {}\n",
    "for song in gram_slices_tp:    \n",
    "    slice_labels = timing_model_labels[song]\n",
    "    pos_labels = [i for i in range(len(slice_labels)) if np.sum(slice_labels[i])>0]\n",
    "    first_pos_label = pos_labels[0]\n",
    "    \n",
    "    slice_tuples = list(zip(*gram_slices_tp[song])) \n",
    "    slices_concat = [np.concatenate(\n",
    "        tup,axis=-1).astype('float32') for tup in slice_tuples][-65:]\n",
    "    while len(slices_concat) < 65:\n",
    "        slices_concat.append(np.zeros((slice_length,140)))\n",
    "    if first_pos_label >= len(slice_labels) - 20:\n",
    "        slices = slices_concat[first_pos_label-20:]\n",
    "        slices += [np.zeros((slice_length,140)) for _ in range(\n",
    "            first_pos_label-(len(slice_labels)-20))]\n",
    "        gram_slices_sbf[song] = slices\n",
    "    elif first_pos_label < 20:\n",
    "        slices = slices_concat[:first_pos_label+20]\n",
    "        slices = [np.zeros((slice_length,140)) for _ in range(20 - first_pos_label)] + slices\n",
    "        gram_slices_sbf[song] = slices\n",
    "    else:\n",
    "        gram_slices_sbf[song] = slices_concat[first_pos_label-20:first_pos_label+20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tm_train_input\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "sbf_fixed_data_train_input = np.stack([np.stack(\n",
    "    gram_slices_sbf[song]) for song in train_set]).astype('float32')\n",
    "sbf_fixed_data_vad_input = np.stack([np.stack(\n",
    "    gram_slices_sbf[song]) for song in vad_set]).astype('float32')\n",
    "sbf_fixed_data_test_input = np.stack([np.stack(\n",
    "    gram_slices_sbf[song]) for song in test_set]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sbf_training_data(batch_inds):\n",
    "    \"\"\"Generates a training batch for input into the outro Start Bar\n",
    "        Finder model by randomly sampling how much the correct \n",
    "        target label should be shifted\"\"\"\n",
    "    batch_size = len(batch_inds)\n",
    "    fixed_batch_input = sbf_fixed_data_train_input[batch_inds]\n",
    "    \n",
    "    batch_targets = random.choices(range(8),k=batch_size)\n",
    "    \n",
    "    batch_input = np.stack(\n",
    "        [fixed_batch_input[i][8-batch_targets[i]:40-batch_targets[i]] \\\n",
    "         for i in range(batch_size)])\n",
    "    \n",
    "    return tf.constant(batch_input,dtype = tf.float64),\\\n",
    "            tf.constant(batch_targets,dtype = tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also build a fixed validation set for evaluation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbf_vad_targets = random.choices(range(8),k=len(vad_set))\n",
    "sbf_vad_input = np.stack(\n",
    "        [sbf_fixed_data_vad_input[i][8-sbf_vad_targets[i]:40-sbf_vad_targets[i]]\\\n",
    "         for i in range(len(vad_set))])\n",
    "\n",
    "sbf_test_targets = random.choices(range(8),k=len(test_set))\n",
    "sbf_test_input = np.stack(\n",
    "        [sbf_fixed_data_test_input[i][8-sbf_test_targets[i]:40-sbf_test_targets[i]]\\\n",
    "         for i in range(len(test_set))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbf_seq_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbf_gram_in = Input((slice_length,140),name = 'sbf_analysis_in')\n",
    "\n",
    "sbf_conv_bar_c = Conv1D(filters = 16,kernel_size = 11,activation = 'relu',strides = 3)\n",
    "sbf_pool_bar_c = MaxPooling1D(pool_size = 2,strides = 2)\n",
    "sbf_bar_out_c = BatchNormalization()(sbf_pool_bar_c(sbf_conv_bar_c(sbf_gram_in)))\n",
    "\n",
    "sbf_conv_bar_2_c = Conv1D(filters = 8,kernel_size = 2,activation = 'relu',strides = 2)\n",
    "sbf_pool_bar_2_c = MaxPooling1D(pool_size = 1,strides =1)\n",
    "sbf_bar_out_2_c = BatchNormalization()(sbf_pool_bar_2_c(sbf_conv_bar_2_c(sbf_bar_out_c)))\n",
    "sbf_bar_out_c_flat = Flatten()(sbf_bar_out_2_c)\n",
    "sbf_gram_model = Model(sbf_gram_in,sbf_bar_out_c_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbf_gram_input = Input((sbf_seq_len,slice_length,140))\n",
    "\n",
    "sbf_gram_flat = Lambda(lambda x: K.reshape(x,(-1,slice_length,140)))(sbf_gram_input)\n",
    "\n",
    "sbf_conv = sbf_gram_model(sbf_gram_flat)\n",
    "\n",
    "sbf_conv_seq = Lambda(lambda x: K.reshape(x,(-1,sbf_seq_len,sbf_conv.shape[-1])))(sbf_conv)\n",
    "\n",
    "\n",
    "sbf_conv_dense = Dense(64,activation='tanh')(Dropout(rate=0.6)(sbf_conv_seq))\n",
    "sbf_conv_dense_2 = Dense(32,activation='tanh')(Dropout(rate=0.6)(sbf_conv_dense))\n",
    "\n",
    "sbf_lstm_out = Bidirectional(\n",
    "    LSTM(32,return_sequences=True,recurrent_dropout = 0.5,dropout=0.5))(sbf_conv_dense_2)\n",
    "sbf_dense_1 = Dense(32,activation='tanh')(Dropout(rate=0.45)(sbf_lstm_out))\n",
    "\n",
    "sbf_zeros = Lambda(lambda x: K.zeros_like(x)[:,:8])(sbf_dense_1)\n",
    "sbf_dense_1_left = Lambda(lambda x: x[:,:-8])(sbf_dense_1)\n",
    "sbf_dense_1_right = Lambda(lambda x: x[:,8:])(sbf_dense_1)\n",
    "sbf_left_attention = Concatenate(axis=1)([sbf_zeros,sbf_dense_1_right])\n",
    "sbf_right_attention = Concatenate(axis=1)([sbf_dense_1_left,sbf_zeros])\n",
    "\n",
    "sbf_dense_1_attention = Concatenate(axis=-1)([sbf_left_attention,sbf_lstm_out,sbf_right_attention])\n",
    "sbf_dense_1_attention_trimmed = Lambda(lambda x: x[:,12:-12])(sbf_dense_1_attention)\n",
    "\n",
    "sbf_dense_2 = Dense(24,activation='tanh')(Dropout(rate=0.5)(sbf_dense_1_attention_trimmed))\n",
    "sbf_dense_3 = Dense(8,activation='tanh')(Dropout(rate=0.4)(sbf_dense_2))\n",
    "sbf_out = Dense(1)(Dropout(rate=0.3)(sbf_dense_3))\n",
    "sbf_out_soft = Activation('softmax')(Lambda(lambda x: x[:,:,0])(sbf_out))\n",
    "sbf_final_model = Model(sbf_gram_input,sbf_out_soft)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "We now build a custom training loop to implement our batch sampling method. We will also need to implement a custom Early Stopping callback to find optimal performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model,inputs,targets):\n",
    "    \"\"\"tf.function for applying gradient updates to the model.\n",
    "        \n",
    "        Args:\n",
    "            model: Keras model to update\n",
    "            inputs: Model inputs used to calculate losses for gradient descent\n",
    "                \n",
    "        Returns:\n",
    "            List of model's losses\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(inputs, training=True)\n",
    "        loss_value = tf.keras.losses.SparseCategoricalCrossentropy()(\n",
    "            targets,pred)\n",
    "        \n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    adam_opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    acc_metric.update_state(targets,pred)\n",
    "    \n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbf_final_model = load_model('outro_start_bar_finder_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_opt = tf.keras.optimizers.Adam(lr = 5e-4)\n",
    "sbf_final_model.compile(optimizer = adam_opt, loss = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sbf_epoch(batch_inds_lst,batch_size):\n",
    "    \"\"\"Runs a single training epoch for the Outro Start Bar Finder model,\n",
    "        keeping track of training loss and accuracy.\n",
    "    \n",
    "        Args:\n",
    "            batch_inds_lst: Shuffled list of training set indices to \n",
    "                be split into batches.\n",
    "            batch_size: Batch size to use for training.\n",
    "        \n",
    "        Returns:\n",
    "            Training/validation accuracy and loss\n",
    "    \"\"\"\n",
    "    batches = [batch_inds_lst[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
    "    \n",
    "    epoch_losses = []\n",
    "    for batch in batches:\n",
    "        \n",
    "        batch_input,batch_target = generate_sbf_training_data(batch)\n",
    "        \n",
    "        loss_value = train_step(sbf_final_model,batch_input,batch_target)\n",
    "        epoch_losses.append(loss_value.numpy())\n",
    "    train_acc = acc_metric.result().numpy()\n",
    "    acc_metric.reset_states()\n",
    "    \n",
    "    training_info.append((np.mean(epoch_losses),train_acc))\n",
    "    \n",
    "    vad_pred = sbf_final_model(sbf_vad_input)\n",
    "    vad_loss = tf.keras.losses.SparseCategoricalCrossentropy()(\n",
    "            sbf_vad_targets,vad_pred)\n",
    "    acc_metric.update_state(sbf_vad_targets,vad_pred)\n",
    "    \n",
    "    vad_acc = acc_metric.result().numpy()\n",
    "    acc_metric.reset_states()\n",
    "    \n",
    "    vad_info.append((vad_loss.numpy(),vad_acc))\n",
    "    return training_info[-1],vad_info[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 600\n",
    "patience = 75\n",
    "patience_counter = 0\n",
    "batch_size = 32\n",
    "num_training_examples = len(train_set)\n",
    "num_batches = num_training_examples//batch_size\n",
    "\n",
    "acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "training_info = []\n",
    "vad_info = []\n",
    "best_vad_acc = 0\n",
    "best_vad_loss = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    batch_inds_lst = list(range(num_training_examples))\n",
    "    batch_inds_lst = random.sample(batch_inds_lst,num_training_examples)\n",
    "    \n",
    "    train_tup,vad_tup = run_sbf_epoch(batch_inds_lst,batch_size)\n",
    "    if epoch == 300:\n",
    "        weights_300 = sbf_final_model.get_weights()\n",
    "    if epoch>=300:\n",
    "        vad_loss = vad_tup[0]\n",
    "        if vad_loss <= best_vad_loss:\n",
    "            best_weights = sbf_final_model.get_weights()\n",
    "            best_epoch = epoch+1\n",
    "            best_train_info = training_info[-1]\n",
    "            patience_counter = 0\n",
    "            best_vad_loss = vad_loss\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "    if patience_counter > patience:\n",
    "        break\n",
    "\n",
    "    print(epoch+1,np.round(time.time()-start,3),training_info[-1],vad_info[-1])\n",
    "sbf_final_model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the performance on our fixed validation and test set data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbf_final_model.compile(optimizer = adam_opt, \n",
    "                        loss = 'sparse_categorical_crossentropy',\n",
    "                        metrics = 'sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1942 - sparse_categorical_accuracy: 0.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.194238305091858, 0.47999998927116394]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbf_final_model.evaluate(sbf_vad_input,np.stack(sbf_vad_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1707 - sparse_categorical_accuracy: 0.5100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1707124710083008, 0.5099999904632568]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbf_final_model.evaluate(sbf_test_input,np.stack(sbf_test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Outro Model\n",
    "We can now combine the two models trained above into an end-to-end process which, given beat and downbeat timestamps alongside chromagram and spectrogram data, can label transition points in the outro of a song. We will construct this process and evaluate overall performance on the test set. First, the transition timing model is used to find the approximate starting point of the transition. Then, if the song was predicted by the Introduction models to have its first downbeat on the first beat of the song, we will calculate the BPM and use it to construct a phrase grid which can be used to identify exact phrase points in the outro. For the remaining songs, the starting point is narrowed down to a single bar by the Start Bar Finder. The madmom downbeat prediction is then used to determine the exact starting beat, and subsequent transition points are identified by 32 beat jumps along with the output of the timing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_test_pred = tm_final_model.predict(tm_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first identify the point in the transition timing model output where the start prediction goes above a certain threshold value. This will indicate approximately where the transition should begin, for use with the Start Bar Finder. We also identify the distance from this point to the correct starting point of the transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pred_inds = {}\n",
    "first_pred_diffs = []\n",
    "for j,song in enumerate(test_set):\n",
    "    tm_start_pred = tm_test_pred[j][:,0]\n",
    "    tm_labels = timing_model_labels[song]\n",
    "    \n",
    "    #Since some songs might have low probability predictions,\n",
    "    #we need to account for these cases when finding the start point\n",
    "    try:\n",
    "        first_pred = [i for i in range(65) if tm_start_pred[i] >= 0.65][0]\n",
    "    except:\n",
    "        try:\n",
    "            first_pred = [i for i in range(65) if tm_start_pred[i] >= 0.55][0]\n",
    "        except:\n",
    "            try:\n",
    "                first_pred = [i for i in range(65) if tm_start_pred[i] >= 0.45][0]\n",
    "            except:\n",
    "                try:\n",
    "                    first_pred = [i for i in range(65) if tm_start_pred[i] >= 0.3][0]\n",
    "                except:\n",
    "                    first_pred = [i for i in range(65) if tm_start_pred[i] >= 0.15][0]\n",
    "    \n",
    "    first_pred_inds[song] = first_pred\n",
    "    pos_labels = [i for i in range(len(tm_labels)) if np.sum(tm_labels[i])>0]\n",
    "    next_label_diff = [i-first_pred for i in pos_labels if i>=first_pred][0]\n",
    "    first_pred_diffs.append(next_label_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then build the input arrays for the Start Bar Finder using these points, and calculate the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_slices_sbf_pred = {}\n",
    "for song in test_set:    \n",
    "    slice_labels = timing_model_labels[song]\n",
    "    \n",
    "    first_pos_label = first_pred_inds[song]\n",
    "    \n",
    "    slice_tuples = list(zip(*gram_slices_tp[song])) \n",
    "    slices_concat = [np.concatenate(\n",
    "        tup,axis=-1).astype('float32') for tup in slice_tuples][-65:]\n",
    "    \n",
    "    while len(slices_concat) < 65:\n",
    "        slices_concat.append(np.zeros((slice_length,140)))\n",
    "    if first_pos_label >= len(slice_labels) - 20:\n",
    "        slices = slices_concat[first_pos_label-20:]\n",
    "        slices += [np.zeros((slice_length,140)) for _ in range(\n",
    "            first_pos_label-(len(slice_labels)-20))]\n",
    "        \n",
    "        gram_slices_sbf_pred[song] = slices[8:]\n",
    "    elif first_pos_label < 20:\n",
    "        slices = slices_concat[:first_pos_label+20]\n",
    "        slices = [np.zeros((slice_length,140)) for _ in range(\n",
    "            20 - first_pos_label)] + slices\n",
    "        gram_slices_sbf_pred[song] = slices[8:]\n",
    "    else:\n",
    "        gram_slices_sbf_pred[song] = slices_concat[first_pos_label-20:first_pos_label+20][8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbf_test_pred_input = np.stack([np.stack(\n",
    "    gram_slices_sbf_pred[song]) for song in test_set]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbf_test_pred = sbf_final_model.predict(sbf_test_pred_input)\n",
    "sbf_test_pred_ind = np.argmax(sbf_test_pred,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we begin the process of generating labels for each song. We first import the timestamp of the first downbeat prediction by the Introduction models for each song in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_downbeat_predictions.pkl','rb') as f:\n",
    "    first_downbeat_pred = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_label_timestamp(song):\n",
    "    \"\"\"Utility function which calculates the timestamp of the\n",
    "    first label in the outro.\"\"\"\n",
    "    \n",
    "    ohs = ohs_dict[song].iloc[:,[0,-2,-1]]\n",
    "    return ohs[(ohs['Outgoing Start']+ohs['Outgoing End'])>=1].values[0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to calculate the BPM of each song to construct our phrase grids. We do this by calculating the BPM across the song in 32 beat slices and taking the mode, in order to account for small irregularities in beat structure in the madmom beat prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bpm(song):\n",
    "    \"\"\"Calculates the BPM of a song by taking the mode across the\n",
    "        32 beat slices\"\"\"\n",
    "    \n",
    "    def get_bpm_slce(song,slce):\n",
    "        \"\"\"Calculates the BPM of a single 32 beat slice of a song using\n",
    "        linear regression.\n",
    "        \n",
    "        Args:\n",
    "            when_beats: beat timestamps\n",
    "            slce: slice index\n",
    "        Returns:\n",
    "            BPM rounded to one decimal place\n",
    "        \"\"\"\n",
    "        when_beats = labels_dict[song].iloc[:,0].apply(float).values[32*slce:32*(slce+1)]\n",
    "        m_res = stats.linregress(np.arange(len(when_beats)),when_beats)\n",
    "        beat_step = m_res.slope\n",
    "        \n",
    "        return np.round(60/beat_step,decimals = 1)\n",
    "    \n",
    "    num_slce = labels_dict[song].shape[0]//32\n",
    "    slce_bpms = [get_bpm_slce(song,i) for i in range(num_slce)]\n",
    "    mode = stats.mode(slce_bpms)[0][0]\n",
    "    if slce_bpms.count(mode) == slce_bpms.count(np.round(mode)):\n",
    "        return np.round(mode)\n",
    "    else:\n",
    "        return mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then build our phrase grids by incrementing in 32-beat jumps, multiplying by the beat length in seconds to determine phrase timestamps. We see that 81 of our 100 songs have been predicted by the Introduction models as having their first downbeat on the first beat. Furthermore, 54 of these 81 songs have their first label in the outro exactly on 32-beat phrase based on the calculated phrase grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs with first downbeat on first beat in Intro: 81\n",
      "Number of first beat songs with exact phrase match on outro label: 54\n"
     ]
    }
   ],
   "source": [
    "downbeat_grids = {}\n",
    "phrase_grids = {}\n",
    "bpms = {}\n",
    "good_beat = []\n",
    "first_beat_songs = []\n",
    "for i,song in enumerate(list(test_set)):\n",
    "    tags = labels_dict[song]\n",
    "    bpm = get_bpm(song)\n",
    "    beat_len = 60/bpm\n",
    "    bpms[song] = bpm\n",
    "    first_beat = tags.values[0,0]\n",
    "    last_beat = tags.values[-1,0]\n",
    "\n",
    "    starting_time = first_downbeat_pred[song]\n",
    "    \n",
    "    phrase_grid = [starting_time + 32*i*beat_len for i in range(-500,500)]\n",
    "    phrase_grid = [x for x in phrase_grid if x>=first_beat and x<=last_beat]\n",
    "\n",
    "    downbeat_grid = [starting_time + 4*i*beat_len for i in range(-500,500)]\n",
    "    downbeat_grid = [x for x in downbeat_grid if x>=first_beat and x<=last_beat]\n",
    "    if starting_time == first_beat:\n",
    "        first_beat_songs.append(song)\n",
    "        first_outro_label_timestamp = get_first_label_timestamp(song)\n",
    "        \n",
    "        if min([abs(x-first_outro_label_timestamp) for x in phrase_grid])<beat_len/3:\n",
    "            good_beat.append(song)\n",
    "    downbeat_grids[song] = downbeat_grid\n",
    "    phrase_grids[song] = phrase_grid\n",
    "    \n",
    "print('Number of songs with first downbeat on first beat in Intro:',len(first_beat_songs))\n",
    "print('Number of first beat songs with exact phrase match on outro label:', len(good_beat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to extract the final labels and evaluate overall performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(prob_pair,threshold = 0.4):\n",
    "    \"\"\"Generates labels based on the transition timing model\n",
    "        output at a single timestep.\n",
    "        \n",
    "        Args:\n",
    "            prob_pair: tuple containing the (start prob,end prob)\n",
    "                predicted by the model\n",
    "            threshold: Threshold probability at which a label \n",
    "                will be generated\n",
    "        Returns:\n",
    "            Label of either Start, End, Start/End, or nan\n",
    "    \"\"\"\n",
    "    start_prob,end_prob = prob_pair\n",
    "    if start_prob > threshold:\n",
    "        if end_prob > threshold:\n",
    "            return 'Start/End'\n",
    "        else:\n",
    "            return 'Start'\n",
    "    elif end_prob > threshold:\n",
    "        return 'End'\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_slice_time_inds(downbeats,slice_times):\n",
    "    \"\"\"Determines the index of the nearest slice to a list of \n",
    "        downbeat/phrase times.\n",
    "    \n",
    "        Args:\n",
    "            downbeats: List of downbeat/phrase timestamps.\n",
    "            slice_times: List of model input slice timestamps\n",
    "        \n",
    "        Returns:\n",
    "            List of indices of same length of downbeats, containing\n",
    "                index of nearest slice to each downbeat\n",
    "    \"\"\"\n",
    "    nearest_slice_time_inds = []\n",
    "    for downbeat in downbeats:\n",
    "        nearest_slice_time_ind = np.argmin([abs(downbeat-x) for x in slice_times])\n",
    "        nearest_slice_time_inds.append(nearest_slice_time_ind)\n",
    "    return nearest_slice_time_inds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the timing of transition points and generate the relevant labels for each song in the test set. As mentioned above, for songs where the Introduction models predict that the first downbeat is on the first beat, we use the phrase grid to determine phrase timings in the outro; otherwise, we use the Start Bar Finder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_song_pred_info = {}\n",
    "for i,song in enumerate(test_set):\n",
    "    \n",
    "    slice_times = gram_slice_times[song]\n",
    "    timing_model_probs = tm_test_pred[i]\n",
    "    \n",
    "    first_pred_ind = first_pred_inds[song]\n",
    "    tags = labels_dict[song]\n",
    "    if len(slice_times)>=64:\n",
    "        outro_slice_times = slice_times[-64:]\n",
    "    else:\n",
    "        outro_slice_times = slice_times\n",
    "        \n",
    "    first_outro_slice_time = outro_slice_times[0]\n",
    "    \n",
    "    if song in first_beat_songs:\n",
    "        phrases = [x for x in phrase_grids[song] if x-first_outro_slice_time > -1]\n",
    "        first_nearest_slice_time_ind = get_nearest_slice_time_inds(phrases,outro_slice_times)[0]\n",
    "        first_nearest_slice_time = outro_slice_times[first_nearest_slice_time_ind]\n",
    "        \n",
    "        try:\n",
    "            nearest_phrase_time = [x for x in phrases if x>outro_slice_times[first_pred_ind-1]][0]\n",
    "        except:\n",
    "            nearest_phrase_time = [x for x in phrases if x>outro_slice_times[first_pred_ind]][0]\n",
    "\n",
    "        phrase_bar_inds = [first_nearest_slice_time_ind+8*j for j in range(-8,8)]\n",
    "        phrase_bar_inds = [x for x in phrase_bar_inds if x < 64 and x>=0]\n",
    "        \n",
    "        nearest_beat_ind = np.argmin([abs(nearest_phrase_time-x) for x in tags.values[:,0]])\n",
    "        phrase_beat_inds = [nearest_beat_ind+j*32 for j in range(-8,8)]\n",
    "        phrase_beat_inds = [x for x in phrase_beat_inds if x<tags.shape[0]]\n",
    "        phrase_beat_inds = phrase_beat_inds[-8:]\n",
    "        \n",
    "        phrase_times = tags.values[phrase_beat_inds,0].tolist()\n",
    "    else:\n",
    "        start_bar_index = first_pred_ind + sbf_test_pred_ind[i]\n",
    "        \n",
    "        start_bar_time = outro_slice_times[start_bar_index-1]\n",
    "        start_bar_beat_index = tags[tags['Beat Timestamp']==start_bar_time].index[0]\n",
    "        \n",
    "        start_bar_tags = tags.iloc[start_bar_beat_index:start_bar_beat_index+4]\n",
    "        start_bar_downbeat_index = start_bar_tags[start_bar_tags['Downbeat']==1].index[0]\n",
    "    \n",
    "                \n",
    "        phrase_bar_inds = [start_bar_index+8*j for j in range(-8,8)]\n",
    "        phrase_bar_inds = [x for x in phrase_bar_inds if x< 64 and x>=0]\n",
    "        \n",
    "        phrase_beat_inds = [start_bar_downbeat_index + j*32 for j in range(-8,8)]\n",
    "        phrase_beat_inds = [x for x in phrase_beat_inds if  x<tags.shape[0]]\n",
    "        phrase_beat_inds = phrase_beat_inds[-8:]\n",
    "        phrase_times = tags.values[phrase_beat_inds,0].tolist()\n",
    "        \n",
    "\n",
    "        \n",
    "    phrase_ind_probs = tm_test_pred[i][phrase_bar_inds,:]\n",
    "    phrase_labels = [get_labels(pair) for pair in phrase_ind_probs]\n",
    "        \n",
    "        \n",
    "    info = list(zip(*(phrase_times,phrase_labels)))\n",
    "    info_df = pd.DataFrame(info,columns = ['Beat Timestamp','Predicted Outro Label'])\n",
    "    test_song_pred_info[song] = info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the resulting labels for an example song, and join on the original labels to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beat Timestamp</th>\n",
       "      <th>Predicted Outro Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162.27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>236.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>251.11</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>265.88</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Beat Timestamp Predicted Outro Label\n",
       "0          162.27                   NaN\n",
       "1          177.03                   NaN\n",
       "2          192.03                   NaN\n",
       "3          206.80                   NaN\n",
       "4          221.57                   NaN\n",
       "5          236.34                   NaN\n",
       "6          251.11                 Start\n",
       "7          265.88                   End"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = \"Redlight - Sports Mode\"\n",
    "test_song_pred_info[song]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beat Timestamp</th>\n",
       "      <th>Predicted Outro Label</th>\n",
       "      <th>Outro Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>236.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>251.11</td>\n",
       "      <td>Start</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>265.88</td>\n",
       "      <td>End</td>\n",
       "      <td>End</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Beat Timestamp Predicted Outro Label Outro Label\n",
       "0          162.27                   NaN         NaN\n",
       "1          177.03                   NaN         NaN\n",
       "2          192.03                   NaN         NaN\n",
       "3          206.80                   NaN         NaN\n",
       "4          221.57                   NaN         NaN\n",
       "5          236.34                   NaN         NaN\n",
       "6          251.11                 Start       Start\n",
       "7          265.88                   End         End"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_label = labels_dict[song].loc[:,['Beat Timestamp','Outro Label']]\n",
    "tags_label = tags_label[tags_label['Outro Label'].apply(lambda x: x in ['Start'])]\n",
    "                                   \n",
    "test_song_pred_info[song].merge(labels_dict[song].loc[:,['Beat Timestamp','Outro Label']].dropna(),\n",
    "                              on = 'Beat Timestamp',how='outer').sort_values('Beat Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the [Introduction Models notebook](2.%20Introduction%20Transition%20Models.ipynb), we can now evaluate performance across the full test set, looking at songs where the labelling is exactly correct along with the downbeat and number of labels. Since the starting point in this case isn't fixed, to evaluate the downbeat we check if there is any overlap between the timestamps predicted and the ones which were manually labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs with downbeat prediction correct: 63\n",
      "Number of songs with same number of transition points: 66\n",
      "Number of songs which are exactly correct: 42\n"
     ]
    }
   ],
   "source": [
    "downbeat_right = []\n",
    "downbeat_diffs = []\n",
    "length_right = []\n",
    "length_diffs = []\n",
    "exact = []\n",
    "first_downbeats = {}\n",
    "for song in test_set:\n",
    "    tags_label = labels_dict[song].loc[:,['Beat Timestamp','Outro Label']]\n",
    "    tags_label = tags_label.dropna().reset_index(drop = True)\n",
    "    pred_df = test_song_pred_info[song].dropna().reset_index(drop = True)\n",
    "    pred_df.columns = ['Beat Timestamp','Outro Label']\n",
    "    first_downbeats[song] = pred_df.values[0,0]\n",
    "    if pred_df.shape[0]>0:\n",
    "        if len(set(tags_label.values[:,0]).intersection(set(pred_df.values[:,0])))>0:\n",
    "            downbeat_right.append(song)\n",
    "        else:\n",
    "            downbeat_diffs.append(tags_label.values[0,0] - pred_df.values[0,0])\n",
    "    if tags_label.shape[0] == pred_df.shape[0]:\n",
    "        length_right.append(song)\n",
    "        if tags_label.equals(pred_df):\n",
    "            exact.append(song)\n",
    "        #We will relax the exact check slightly by allowing 'Start/End' to be \n",
    "        #equal to 'Start' or 'End'\n",
    "        elif tags_label.replace('Start/End','Start').equals(pred_df.replace('Start/End','Start')):\n",
    "            exact.append(song)\n",
    "        elif tags_label.replace('Start/End','End').equals(pred_df.replace('Start/End','End')):\n",
    "                exact.append(song)\n",
    "    else:\n",
    "        length_diffs.append((song,tags_label.shape[0] - pred_df.shape[0]))\n",
    "\n",
    "            \n",
    "print('Number of songs with downbeat prediction correct:',len(downbeat_right))\n",
    "print('Number of songs with same number of transition points:',len(length_right))\n",
    "print('Number of songs which are exactly correct:', len(exact))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the Introduction models, the downbeat prediction is the key part of the prediction, as if it is incorrect then the timing of the transitions will be either off-downbeat or off-phrase. However, if this is correct, then there is some subjectivity to the timing of the transition. A manual review of the 21 songs which had the correct downbeat but were not an exact match found that 15 of them had appropriate transitions, with the inference of some missing labels based on simple rules (as explained in the [Introduction Models notebook](2.%20Introduction%20Transition%20Models.ipynb). Two examples of these are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:\n",
      "   Beat Timestamp Predicted Outro Label\n",
      "0          304.79                 Start\n",
      "1          320.03                   End\n",
      "2          335.26                   End\n",
      "\n",
      "Manual Label:\n",
      "   Beat Timestamp Outro Label\n",
      "0          274.32       Start\n",
      "1          289.55         End\n",
      "2          304.79   Start/End\n",
      "3          320.03         End\n",
      "4          335.26         End\n"
     ]
    }
   ],
   "source": [
    "ex_song_1 = 'Motez - Roll Out (Benson Remix)'\n",
    "print('Predicted Label:')\n",
    "print(test_song_pred_info[ex_song_1].dropna().reset_index(drop=True))\n",
    "print('\\nManual Label:')\n",
    "print(labels_dict[ex_song_1].loc[:,['Beat Timestamp','Outro Label']]\\\n",
    "      .dropna().reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:\n",
      "   Beat Timestamp Predicted Outro Label\n",
      "0          377.96                   End\n",
      "1          393.08                   End\n",
      "2          408.20                   End\n",
      "3          423.34                   End\n",
      "\n",
      "Manual Label:\n",
      "   Beat Timestamp Outro Label\n",
      "0          362.85       Start\n",
      "1          377.96         End\n",
      "2          393.08         End\n",
      "3          408.20         End\n",
      "4          423.34         End\n"
     ]
    }
   ],
   "source": [
    "ex_song_2 = 'Green Velvet & Mauro Venti - Share Now'\n",
    "print('Predicted Label:')\n",
    "print(test_song_pred_info[ex_song_2].dropna().reset_index(drop=True))\n",
    "print('\\nManual Label:')\n",
    "print(labels_dict[ex_song_2].loc[:,['Beat Timestamp','Outro Label']]\\\n",
    "      .dropna().reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with 57 songs which have been labelled with high quality outro transition timings; 43 of these songs were also labelled correctly by the Introduction models, meaning we have 43 songs which are labelled completely for use in transitions. As discussed above, labelling the outro is more difficult than labelling the introduction, since the start of the song is not as useful a reference point. Future work should focus on identifying the downbeat correctly, and perhaps seeing if there is a more effective way to combine the phrase grid structure and the output of the Start Bar Finder. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tensorflow",
   "language": "python",
   "name": "conda-env-py37_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
